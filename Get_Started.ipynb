{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./pics/dd_logo.png) \n",
    "\n",
    "# Getting started\n",
    "\n",
    "**deep**doctection is a package that can be used to extract text from complex structured documents. These can be native PDFs but also scans. In contrast to various text miners **deep**doctection makes use of deep learning models from powerful third party libraries for solving OCR, vision or language embedding problems. \n",
    "\n",
    "This notebook will give you a quick tour so that you can get started straight away. \n",
    "\n",
    "If you are running this notebook on Colab and you haven't installed it before by yourself, simply activate the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dataflow@ git+https://github.com/tensorpack/dataflow.git\n",
      "  Cloning https://github.com/tensorpack/dataflow.git to /private/var/folders/x2/hv4cc0kd50x399jfl74yd62c0000gn/T/pip-install-ghgdyzpx/dataflow_4c5621080e02436a8184126ae709899c\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/tensorpack/dataflow.git /private/var/folders/x2/hv4cc0kd50x399jfl74yd62c0000gn/T/pip-install-ghgdyzpx/dataflow_4c5621080e02436a8184126ae709899c\n",
      "  Resolved https://github.com/tensorpack/dataflow.git to commit 4ac75d6b000c887b68bbc4ace11c57a47eff662c\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.14 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from dataflow@ git+https://github.com/tensorpack/dataflow.git) (1.24.1)\n",
      "Requirement already satisfied: six in /opt/homebrew/opt/six/lib/python3.11/site-packages (from dataflow@ git+https://github.com/tensorpack/dataflow.git) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from dataflow@ git+https://github.com/tensorpack/dataflow.git) (2.2.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from dataflow@ git+https://github.com/tensorpack/dataflow.git) (0.9.0)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from dataflow@ git+https://github.com/tensorpack/dataflow.git) (4.64.1)\n",
      "Requirement already satisfied: msgpack>=0.5.2 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from dataflow@ git+https://github.com/tensorpack/dataflow.git) (1.0.4)\n",
      "Requirement already satisfied: msgpack-numpy>=0.4.4.2 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from dataflow@ git+https://github.com/tensorpack/dataflow.git) (0.4.8)\n",
      "Requirement already satisfied: pyzmq>=16 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from dataflow@ git+https://github.com/tensorpack/dataflow.git) (24.0.1)\n",
      "Requirement already satisfied: psutil>=5 in /opt/homebrew/Cellar/jupyterlab/3.4.8_1/libexec/lib/python3.11/site-packages (from dataflow@ git+https://github.com/tensorpack/dataflow.git) (5.9.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install  \"dataflow @ git+https://github.com/tensorpack/dataflow.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepdoctection\n",
      "  Using cached deepdoctection-0.21-py3-none-any.whl (512 kB)\n",
      "Collecting apted==1.0.3\n",
      "  Using cached apted-1.0.3-py3-none-any.whl (40 kB)\n",
      "Collecting catalogue==2.0.7\n",
      "  Using cached catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
      "Collecting distance==0.1.3\n",
      "  Using cached Distance-0.1.3.tar.gz (180 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25hCollecting huggingface-hub<0.11.0,>=0.4.0\n",
      "  Using cached huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
      "Collecting importlib-metadata>=4.11.2\n",
      "  Using cached importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n",
      "Collecting jsonlines==3.0.0\n",
      "  Using cached jsonlines-3.0.0-py3-none-any.whl (8.5 kB)\n",
      "Collecting lxml>=4.9.1\n",
      "  Using cached lxml-4.9.2.tar.gz (3.7 MB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25hCollecting mock==4.0.3\n",
      "  Using cached mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Collecting networkx>=2.7.1\n",
      "  Using cached networkx-3.0-py3-none-any.whl (2.0 MB)\n",
      "Collecting numpy<1.24,>=1.21\n",
      "  Using cached numpy-1.23.5-cp311-cp311-macosx_11_0_arm64.whl (13.3 MB)\n",
      "Collecting opencv-python==4.5.4.60\n",
      "  Using cached opencv-python-4.5.4.60.tar.gz (89.8 MB)\n",
      "  Installing build dependencies ... \u001B[?25lerror\n",
      "  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\n",
      "  \n",
      "  \u001B[31m×\u001B[0m \u001B[32mpip subprocess to install build dependencies\u001B[0m did not run successfully.\n",
      "  \u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\n",
      "  \u001B[31m╰─>\u001B[0m \u001B[31m[19 lines of output]\u001B[0m\n",
      "  \u001B[31m   \u001B[0m Ignoring numpy: markers 'python_version == \"3.6\" and platform_machine != \"aarch64\" and platform_machine != \"arm64\"' don't match your environment\n",
      "  \u001B[31m   \u001B[0m Ignoring numpy: markers 'python_version == \"3.7\" and platform_machine != \"aarch64\" and platform_machine != \"arm64\"' don't match your environment\n",
      "  \u001B[31m   \u001B[0m Ignoring numpy: markers 'python_version == \"3.8\" and platform_machine != \"aarch64\" and platform_machine != \"arm64\"' don't match your environment\n",
      "  \u001B[31m   \u001B[0m Ignoring numpy: markers 'python_version <= \"3.9\" and sys_platform == \"linux\" and platform_machine == \"aarch64\"' don't match your environment\n",
      "  \u001B[31m   \u001B[0m Ignoring numpy: markers 'python_version <= \"3.9\" and sys_platform == \"darwin\" and platform_machine == \"arm64\"' don't match your environment\n",
      "  \u001B[31m   \u001B[0m Ignoring numpy: markers 'python_version == \"3.9\" and platform_machine != \"aarch64\" and platform_machine != \"arm64\"' don't match your environment\n",
      "  \u001B[31m   \u001B[0m Collecting setuptools\n",
      "  \u001B[31m   \u001B[0m   Using cached setuptools-67.2.0-py3-none-any.whl (1.1 MB)\n",
      "  \u001B[31m   \u001B[0m Collecting wheel\n",
      "  \u001B[31m   \u001B[0m   Using cached wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "  \u001B[31m   \u001B[0m Collecting scikit-build\n",
      "  \u001B[31m   \u001B[0m   Using cached scikit_build-0.16.6-py3-none-any.whl (79 kB)\n",
      "  \u001B[31m   \u001B[0m Collecting cmake\n",
      "  \u001B[31m   \u001B[0m   Using cached cmake-3.25.2-py2.py3-none-macosx_10_10_universal2.macosx_10_10_x86_64.macosx_11_0_arm64.macosx_11_0_universal2.whl (45.1 MB)\n",
      "  \u001B[31m   \u001B[0m Collecting pip\n",
      "  \u001B[31m   \u001B[0m   Using cached pip-23.0-py3-none-any.whl (2.1 MB)\n",
      "  \u001B[31m   \u001B[0m ERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\n",
      "  \u001B[31m   \u001B[0m ERROR: Could not find a version that satisfies the requirement numpy==1.21.2 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0rc1, 1.23.0rc2, 1.23.0rc3, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0rc1, 1.24.0rc2, 1.24.0, 1.24.1, 1.24.2)\n",
      "  \u001B[31m   \u001B[0m ERROR: No matching distribution found for numpy==1.21.2\n",
      "  \u001B[31m   \u001B[0m \u001B[31m[end of output]\u001B[0m\n",
      "  \n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\n",
      "\n",
      "\u001B[31m×\u001B[0m \u001B[32mpip subprocess to install build dependencies\u001B[0m did not run successfully.\n",
      "\u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\n",
      "\u001B[31m╰─>\u001B[0m See above for output.\n",
      "\n",
      "\u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001B[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install deepdoctection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#!apt-get install -y tesseract-ocr tesseract-ocr-deu\n",
    "#!apt-get install poppler-utils\n",
    "#!pip install -e git+https://github.com/deepdoctection/deepdoctection.git#egg=deepdoctection[source-pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import deepdoctection as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample\n",
    "\n",
    "Take an image (e.g. .png, .jpg, ...). If you take the example below you'll maybe need to change ```image_path```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "image_path = Path.cwd() / \"pics/samples/sample_2/sample_2.png\"\n",
    "image = cv2.imread(image_path.as_posix())\n",
    "plt.figure(figsize = (25,17))\n",
    "plt.axis('off')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./pics/samples/sample_2/sample_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzer\n",
    "\n",
    "Next, we instantiate the **deep**doctection analyzer. There is a built-in pipeline you can use. The analyzer is an example of a pipeline that can be built depending on the problem you want to tackle. This particular pipeline is built from various building blocks as shown in the diagram. \n",
    "\n",
    "There is a lot going on under the hood. The analyzer calls three object detectors to structure the page and an OCR engine to extract the text. However, this is clearly not enough. On top of that, words have to be mapped to layout structures and a reading order has to be inferred. \n",
    "\n",
    "![title](./pics/dd_pipeline.png)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = dd.get_dd_analyzer(language='deu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The language of the sample is german and passing the argument `language='deu'` will use a Tesseract model that has been trained on a german corpus giving much better result than the default english version.\n",
    "\n",
    "## Analyze methods\n",
    "\n",
    "Once all models have been loaded, we can process single pages or documents. You can either set `path=path/to/dir` if you have a folder of scans or `path=path/to/my/doc.pdf` if you have a single pdf document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "path = Path.cwd() / \"pics/samples/sample_2\"\n",
    "\n",
    "df = analyzer.analyze(path=path)\n",
    "df.reset_state()  # This method must be called just before starting the iteration. It is part of the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see when activating the cell that not much has happened yet. The reason is that `analyze` is a generator function. We need a `for`-loop or `next` to start the process.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "doc=iter(df)\n",
    "page = next(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page\n",
    "\n",
    "Let's see what we got back. We start with some header information about the page. With `get_attribute_names()` you get a list of all attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "page.height, page.width, page.file_name, page.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "page.get_attribute_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`page.document_type` returns None. The reason is that this pipeline is not built for document classification. You can easily build a pipeline containing a document classifier, though. Check this [notebook](Using_LayoutLM_for_sequence_classification.ipynb) for further information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page.document_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the detected segments. If you set `interactive=True` a viewer will pop up. Use + and - to zoom out/in. Use q to close the page.\n",
    "\n",
    "Alternatively, you can visualize the output with matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = page.viz()\n",
    "plt.figure(figsize = (25,17))\n",
    "plt.axis('off')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./pics/output_16_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at other attributes. We can use the `text` property to get the content of the document. You will notice that the table is not included. You can therefore filter tables from the other content. In fact you can even filter on every layout segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layout in page.layouts:\n",
    "    if layout.category_name==\"title\":\n",
    "        print(f\"Title: {layout.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tables are stored in `page.tables` which is a python list of table objects. Obviously, only one table has been detected. Let's have a closer look at the table. Most attributes are hopefully self explained. If you `print(page.tables)` you will get a very cryptic `__repr__` output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(page.tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = page.tables[0]\n",
    "table.get_attribute_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.number_of_rows, table.number_of_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(table.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go deeper down the rabbit hole. A `Table` has cells and we can even get the text of one particular cell. Note that the output list is not sorted by row or column. You have to do it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = table.cells[0]\n",
    "cell.get_attribute_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell.column_number, cell.row_number, cell.text, cell.annotation_id  # every object comes with a unique annotation_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not down yet, we have a list of words that is responsible to generate the text string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = cell.words[0]\n",
    "word.get_attribute_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reading order determines the string position. OCR engines generally provide a some heuristics to infer a reading order. This library, however, follows the apporach to disentangle every processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word.characters, word.reading_order, word.token_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Page` object is read-only and even though you can change the value it will not be persisted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word.token_class = \"ORG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word #  __repr__ of the base object does carry <WordType.token_class> information.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save your result in a big `.json` file. The default `save` configuration will store the image as b64 encoded string, so be aware: The `.json` file with that image has a size of 6,2 MB!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having saved the results you can easily parse the file into the `Page` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd() / \"pics/samples/sample_2/sample_2.json\"\n",
    "\n",
    "df = dd.SerializerJsonlines.load(path)\n",
    "page = dd.Page.from_dict(**next(iter(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
